{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe7bbac",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "[Hacker News](https://news.ycombinator.com/) is a site where user-submitted stories (known as \"posts\") are voted and commented upon. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`:\n",
    "\n",
    "`Ask HN` - These are posts that users submit to ask the Hacker News community a specific question.\n",
    "`Show HN` - These are posts that users submit to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "In our analysis, we'll compare these two types of posts to determine the following:\n",
    "\n",
    "* Do `Ask HN` or `Show HN` posts receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "First we'll read in our [dataset](https://www.kaggle.com/hacker-news/hacker-news-posts) (a description of what each column contains can be found by following the link).\n",
    "This dataset contains approximately 300,000 rows and contains information such as the link that a post points to, the votes they have been awarded and how many comments they have received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c8d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n"
     ]
    }
   ],
   "source": [
    "# Read in the Data\n",
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv', encoding='utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb30cc",
   "metadata": {},
   "source": [
    "# Removing Headers from a List of Lists\n",
    "\n",
    "Notice the first list in the inner lists contains the column headers, and the lists after contain the data for a given row. In order to analyse our data, we need to first remove the row containing the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f04ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "# Remove the headers.\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113426b",
   "metadata": {},
   "source": [
    "# Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Since we're only concerned with post titles beginning with `Ask HN` or `Show HN`, we'll create new lists of lists containing just the data for those titles.\n",
    "\n",
    "To find the desired posts, we'll use the string method `startswith`, while accounting for variations in capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b60573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n",
      "273822\n"
     ]
    }
   ],
   "source": [
    "# Identify posts that begin with either `Ask HN` or `Show HN` and separate into different lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81744aa9",
   "metadata": {},
   "source": [
    "Below are the first five rows in the new `ask_posts` list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a262dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "\n",
      "\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "\n",
      "\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in ask_posts[:5]:\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e85d8c",
   "metadata": {},
   "source": [
    "Below are the first five rows in thw `show_posts` list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b102ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "\n",
      "\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "\n",
      "\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "\n",
      "\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "\n",
      "\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b5f09",
   "metadata": {},
   "source": [
    "# Calculating the Average Number of Comments for Ask HN and Show HN Posts\n",
    "\n",
    "Now we'll determine if `Ask HN` posts or `Show HN` posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b76230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of comments on `Ask HN` posts.\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36eee7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of comments on `Show HN` posts.\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e754066",
   "metadata": {},
   "source": [
    "As we can see from the results above, `Ask HN` posts receive a much higher number of comments on average than `Show HN` posts.\n",
    "\n",
    "# Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Since `Ask HN` posts are more likely to receive comments, we'll focus our remaining analysis on these posts.\n",
    "\n",
    "During the second part of our analysis, we'll determine whether `Ask HN` posts created at a certain time are more likely to attract comments. We'll carry out the following steps:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "Below, we'll tackle the first step - calculating the amount of `Ask HN` posts and comments received by hour created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a47c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amount of ask posts created during each hour of the day and the number of comments received.\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    num_comments = row[1]\n",
    "    hour = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ad92c",
   "metadata": {},
   "source": [
    "# Calculating the Average Number of Comments for Ask HN Posts by Hour\n",
    "\n",
    "Above, we created two dictionaries:\n",
    "\n",
    "* `counts_by_hour`: contains the number of `Ask HN` posts created during each hour of the day.\n",
    "* `comments_by_hour`: contains the corresponding total number of comments `Ask HN` posts created at each hour recieved\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f79284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average number of comments that `Ask HN` posts created at each hour of the day receive.\n",
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr, comments_by_hour[hr] / counts_by_hour[hr]])\n",
    "\n",
    "print(avg_by_hour)\n",
    "   \n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc6528",
   "metadata": {},
   "source": [
    "# Sorting and Printing Values from a List of Lists\n",
    "\n",
    "Although we now have the results we need to discern the average number of comments for posts created during each hour of the day, the format above makes it difficult to identify the hours with the highest averages.\n",
    "We'll finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bef532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n"
     ]
    }
   ],
   "source": [
    "# Sort the list of lists in descending order.\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc093434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Print the top results in a readable format.\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "template = \"{hour}: {avg:.2f} average comments per post\"\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\").strftime(\"%H:%M\")\n",
    "    avg = row[0]\n",
    "    formatted_result = template.format(hour=hour, avg=avg)\n",
    "    print(formatted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e63ef",
   "metadata": {},
   "source": [
    "We can see here that the hour with the highest average number of comments per post is 15:00. According to the [dataset documentation](https://www.kaggle.com/hacker-news/hacker-news-posts/), the timezone is set to US Eastern Time.\n",
    "This translates to 20:00 British Summer Time.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "In this project, we analysed `Ask HN` and `Show HN` posts on [Hacker News](https://news.ycombinator.com/) to determine which type of posts created at which time recieve the most comments on average.\n",
    "Based on our analysis, to maximise the engagement of a post, we'd recommend that it be catagorised as an `Ask HN` post and created between the hours of 20:00 and 21:00 BST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
